{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13155309,"sourceType":"datasetVersion","datasetId":8335225}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import all required libraries for image preprocessing\nimport os                          # For file system operations\nimport numpy as np                 # For numerical operations\nimport pandas as pd                # For data manipulation\nimport matplotlib.pyplot as plt    # For plotting visualizations\nfrom PIL import Image, ImageEnhance  # For image loading and enhancement\nimport cv2                         # For advanced image processing\nfrom sklearn.preprocessing import LabelEncoder  # For encoding class labels\nfrom sklearn.model_selection import train_test_split  # For data splitting\nimport tensorflow as tf           # For deep learning operations\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator  # For augmentation\nimport random                     # For random operations\nimport warnings                   # To handle warnings\nwarnings.filterwarnings('ignore')  # Suppress warning messages\n\n# Set random seed for reproducible results\nnp.random.seed(42)\ntf.random.set_seed(42)\nrandom.seed(42)\n\nprint(\" All libraries imported successfully\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-25T18:37:40.538866Z","iopub.execute_input":"2025-09-25T18:37:40.539826Z","iopub.status.idle":"2025-09-25T18:37:40.545566Z","shell.execute_reply.started":"2025-09-25T18:37:40.539800Z","shell.execute_reply":"2025-09-25T18:37:40.544831Z"}},"outputs":[{"name":"stdout","text":" All libraries imported successfully\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Define the dataset path\ndataset_path = '/kaggle/input/pre-process-data/For-pre-process'\n\n# Display dataset path\nprint(\" Dataset path:\", dataset_path)\n\n# Function to explore dataset structure\ndef explore_dataset():\n    \"\"\"Explore the dataset structure and count images in each category\"\"\"\n    print(\"\\n Exploring dataset structure...\")\n    \n    # Get all category folders\n    categories = []\n    total_images = 0\n    \n    # Loop through each item in dataset directory\n    for item in os.listdir(dataset_path):\n        item_path = os.path.join(dataset_path, item)\n        \n        # Check if item is a directory (category folder)\n        if os.path.isdir(item_path):\n            # Count image files in category\n            image_files = [f for f in os.listdir(item_path) \n                          if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]\n            image_count = len(image_files)\n            \n            categories.append(item)\n            total_images += image_count\n            print(f\" {item}: {image_count} images\")\n\n    print(f\"\\n Total categories: {len(categories)}\")\n    print(f\" Total images: {total_images}\")\n    print(f\" Categories: {categories}\")\n    \n    return categories, total_images\n\n# Explore the dataset\ncategories, total_count = explore_dataset()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T18:37:47.859287Z","iopub.execute_input":"2025-09-25T18:37:47.859535Z","iopub.status.idle":"2025-09-25T18:37:47.998995Z","shell.execute_reply.started":"2025-09-25T18:37:47.859517Z","shell.execute_reply":"2025-09-25T18:37:47.998235Z"}},"outputs":[{"name":"stdout","text":" Dataset path: /kaggle/input/pre-process-data/For-pre-process\n\n Exploring dataset structure...\n metal: 2000 images\n glass: 2000 images\n paper: 2000 images\n cardboard: 2000 images\n plastic: 2000 images\n\n Total categories: 5\n Total images: 10000\n Categories: ['metal', 'glass', 'paper', 'cardboard', 'plastic']\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Function to load and validate images\ndef load_image(image_path):\n    \"\"\"Load image from path and convert to RGB format\"\"\"\n    try:\n        # Open image using PIL\n        image = Image.open(image_path)\n        \n        # Convert to RGB if image has different format\n        if image.mode != 'RGB':\n            image = image.convert('RGB')\n        \n        # Check minimum size (filter very small images)\n        if image.size[0] < 50 or image.size[1] < 50:\n            return None\n            \n        return image\n    except Exception as e:\n        # Return None if image cannot be loaded\n        print(f\" Error loading {image_path}: {e}\")\n        return None\n\n# Function to resize images to target size\ndef resize_image(image, target_size=(256, 256)):\n    \"\"\"Resize image to specified dimensions\"\"\"\n    # Use LANCZOS resampling for better quality\n    resized = image.resize(target_size, Image.Resampling.LANCZOS)\n    return resized\n\n# Function to convert PIL image to numpy array\ndef image_to_array(image):\n    \"\"\"Convert PIL image to numpy array\"\"\"\n    # Convert PIL image to numpy array\n    img_array = np.array(image)\n    return img_array\n\n# Function to normalize pixel values\ndef normalize_image(image_array):\n    \"\"\"Normalize pixel values from 0-255 to 0-1 range\"\"\"\n    # Convert to float and divide by 255 to get 0-1 range\n    normalized = image_array.astype(np.float32) / 255.0\n    return normalized\n\nprint(\" Image processing functions defined successfully\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T18:37:51.285432Z","iopub.execute_input":"2025-09-25T18:37:51.286159Z","iopub.status.idle":"2025-09-25T18:37:51.295271Z","shell.execute_reply.started":"2025-09-25T18:37:51.286125Z","shell.execute_reply":"2025-09-25T18:37:51.294426Z"}},"outputs":[{"name":"stdout","text":" Image processing functions defined successfully\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Function to apply zoom augmentation\ndef apply_zoom(image, zoom_range=(0.8, 1.2)):\n    \"\"\"Apply random zoom in/out to image\"\"\"\n    zoom_factor = random.uniform(zoom_range[0], zoom_range[1])\n    \n    # Get image dimensions\n    width, height = image.size\n    \n    if zoom_factor < 1.0:\n        # Zoom out - resize smaller and pad with white\n        new_width = int(width * zoom_factor)\n        new_height = int(height * zoom_factor)\n        resized = image.resize((new_width, new_height), Image.Resampling.LANCZOS)\n        \n        # Create white background and paste resized image in center\n        zoomed = Image.new('RGB', (width, height), (255, 255, 255))\n        x_offset = (width - new_width) // 2\n        y_offset = (height - new_height) // 2\n        zoomed.paste(resized, (x_offset, y_offset))\n        return zoomed\n    else:\n        # Zoom in - resize larger and crop center\n        new_width = int(width * zoom_factor)\n        new_height = int(height * zoom_factor)\n        resized = image.resize((new_width, new_height), Image.Resampling.LANCZOS)\n        \n        # Crop center to original size\n        x_offset = (new_width - width) // 2\n        y_offset = (new_height - height) // 2\n        return resized.crop((x_offset, y_offset, x_offset + width, y_offset + height))\n\n# Function to apply rotation augmentation\ndef apply_rotation(image, angle_range=(-30, 30)):\n    \"\"\"Apply random rotation to image\"\"\"\n    # Get random angle in specified range\n    angle = random.uniform(angle_range[0], angle_range[1])\n    # Rotate image with white background fill\n    rotated = image.rotate(angle, expand=True, fillcolor=(255, 255, 255))\n    return rotated\n\n# Function to apply brightness augmentation\ndef apply_brightness(image, brightness_range=(0.7, 1.3)):\n    \"\"\"Apply random brightness adjustment\"\"\"\n    # Create brightness enhancer\n    enhancer = ImageEnhance.Brightness(image)\n    # Get random brightness factor\n    factor = random.uniform(brightness_range[0], brightness_range[1])\n    # Apply brightness adjustment\n    brightened = enhancer.enhance(factor)\n    return brightened\n\n# Function to apply random augmentation\ndef apply_augmentation(image, augment_type='random'):\n    \"\"\"Apply specified augmentation type to image\"\"\"\n    if augment_type == 'random':\n        # Randomly choose augmentation type\n        aug_choice = random.choice(['zoom', 'rotate', 'brightness'])\n    else:\n        aug_choice = augment_type\n    \n    # Apply selected augmentation\n    if aug_choice == 'zoom':\n        augmented = apply_zoom(image)\n    elif aug_choice == 'rotate':\n        augmented = apply_rotation(image)\n        # Resize after rotation to maintain target size\n        augmented = resize_image(augmented)\n    elif aug_choice == 'brightness':\n        augmented = apply_brightness(image)\n    else:\n        augmented = image  # No augmentation\n    \n    return augmented\n\nprint(\" Augmentation functions defined successfully\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T18:37:54.658091Z","iopub.execute_input":"2025-09-25T18:37:54.658364Z","iopub.status.idle":"2025-09-25T18:37:54.669599Z","shell.execute_reply.started":"2025-09-25T18:37:54.658343Z","shell.execute_reply":"2025-09-25T18:37:54.668676Z"}},"outputs":[{"name":"stdout","text":" Augmentation functions defined successfully\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Function to create label encoder for categories\ndef create_label_encoder(categories):\n    \"\"\"Create and fit label encoder for garbage categories\"\"\"\n    # Create label encoder instance\n    label_encoder = LabelEncoder()\n    \n    # Fit encoder with category names\n    label_encoder.fit(categories)\n    \n    # Display label mappings\n    print(\" Label Encoding Mappings:\")\n    for i, category in enumerate(categories):\n        encoded_label = label_encoder.transform([category])[0]\n        print(f\"   {category} → {encoded_label}\")\n    \n    return label_encoder\n\n# Function to encode category name to numerical label\ndef encode_label(category, label_encoder):\n    \"\"\"Convert category name to numerical label\"\"\"\n    encoded = label_encoder.transform([category])[0]\n    return encoded\n\n# Function to decode numerical label back to category name\ndef decode_label(encoded_label, label_encoder):\n    \"\"\"Convert numerical label back to category name\"\"\"\n    decoded = label_encoder.inverse_transform([encoded_label])[0]\n    return decoded\n\n# Create label encoder for the dataset\nif categories:\n    label_encoder = create_label_encoder(categories)\n    print(f\"\\n Label encoder created for {len(categories)} categories\")\nelse:\n    print(\" No categories found to encode\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T18:37:57.857445Z","iopub.execute_input":"2025-09-25T18:37:57.857723Z","iopub.status.idle":"2025-09-25T18:37:57.864684Z","shell.execute_reply.started":"2025-09-25T18:37:57.857701Z","shell.execute_reply":"2025-09-25T18:37:57.863963Z"}},"outputs":[{"name":"stdout","text":" Label Encoding Mappings:\n   metal → 2\n   glass → 1\n   paper → 3\n   cardboard → 0\n   plastic → 4\n\n Label encoder created for 5 categories\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Function to process single image through complete pipeline\ndef preprocess_single_image(image_path, category, label_encoder, apply_augment=False):\n    \"\"\"\n    Complete preprocessing pipeline for single image:\n    1. Load image\n    2. Resize to 256x256\n    3. Apply augmentation (optional)\n    4. Convert to array\n    5. Normalize pixel values\n    6. Encode label\n    \"\"\"\n    # Step 1: Load image\n    image = load_image(image_path)\n    if image is None:\n        return None, None\n    \n    # Step 2: Resize image to 256x256\n    resized_image = resize_image(image, target_size=(256, 256))\n    \n    # Step 3: Apply augmentation if requested\n    if apply_augment:\n        processed_image = apply_augmentation(resized_image)\n        # Ensure size is still 256x256 after augmentation\n        processed_image = resize_image(processed_image, target_size=(256, 256))\n    else:\n        processed_image = resized_image\n    \n    # Step 4: Convert PIL image to numpy array\n    image_array = image_to_array(processed_image)\n    \n    # Step 5: Normalize pixel values to 0-1 range\n    normalized_array = normalize_image(image_array)\n    \n    # Step 6: Encode category label to numerical value\n    encoded_label = encode_label(category, label_encoder)\n    \n    return normalized_array, encoded_label\n\n# Function to process entire dataset\ndef process_complete_dataset(dataset_path, categories, label_encoder, augment_original=True):\n    \"\"\"Process complete dataset through preprocessing pipeline\"\"\"\n    print(\" Starting complete dataset preprocessing...\")\n    \n    # Initialize lists to store processed data\n    processed_images = []      # Store normalized image arrays\n    processed_labels = []      # Store encoded labels\n    processing_stats = {}      # Store processing statistics\n    \n    # Process each category\n    for category in categories:\n        print(f\"\\n Processing category: {category}\")\n        \n        category_path = os.path.join(dataset_path, category)\n        \n        # Get all image files in category\n        image_files = [f for f in os.listdir(category_path)\n                      if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]\n        \n        # Initialize category statistics\n        original_count = len(image_files)\n        processed_count = 0\n        augmented_count = 0\n        failed_count = 0\n        \n        # Process each image in category\n        for filename in image_files:\n            image_path = os.path.join(category_path, filename)\n            \n            # Process original image (without augmentation)\n            img_array, label = preprocess_single_image(\n                image_path, category, label_encoder, apply_augment=False\n            )\n            \n            if img_array is not None:\n                processed_images.append(img_array)\n                processed_labels.append(label)\n                processed_count += 1\n                \n                # Create augmented version if requested\n                if augment_original:\n                    aug_img_array, aug_label = preprocess_single_image(\n                        image_path, category, label_encoder, apply_augment=True\n                    )\n                    \n                    if aug_img_array is not None:\n                        processed_images.append(aug_img_array)\n                        processed_labels.append(aug_label)\n                        augmented_count += 1\n            else:\n                failed_count += 1\n        \n        # Store category statistics\n        processing_stats[category] = {\n            'original': original_count,\n            'processed': processed_count,\n            'augmented': augmented_count,\n            'failed': failed_count,\n            'total_output': processed_count + augmented_count\n        }\n        \n        print(f\"    {category}: {original_count} → {processed_count + augmented_count} images\")\n        print(f\"       Original: {processed_count}, Augmented: {augmented_count}, Failed: {failed_count}\")\n    \n    # Convert lists to numpy arrays\n    X_processed = np.array(processed_images)  # Image data\n    y_processed = np.array(processed_labels)  # Labels\n    \n    print(f\"\\n Dataset preprocessing completed!\")\n    print(f\" Final dataset shape: {X_processed.shape}\")\n    print(f\" Labels shape: {y_processed.shape}\")\n    print(f\" Total images: {len(X_processed)}\")\n    \n    return X_processed, y_processed, processing_stats\n\nprint(\" Complete preprocessing pipeline defined successfully\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T18:38:01.505478Z","iopub.execute_input":"2025-09-25T18:38:01.506086Z","iopub.status.idle":"2025-09-25T18:38:01.516628Z","shell.execute_reply.started":"2025-09-25T18:38:01.506059Z","shell.execute_reply":"2025-09-25T18:38:01.515695Z"}},"outputs":[{"name":"stdout","text":" Complete preprocessing pipeline defined successfully\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Execute the complete preprocessing pipeline\nprint(\" Executing complete preprocessing pipeline...\")\nprint(\"=\" * 60)\n\n# Process the dataset\nX_data, y_data, stats = process_complete_dataset(\n    dataset_path, categories, label_encoder, augment_original=True\n)\n\n# Display final statistics\nprint(\"\\n\" + \"=\" * 60)\nprint(\" FINAL PROCESSING RESULTS:\")\nprint(\"=\" * 60)\n\ntotal_original = sum([stats[cat]['original'] for cat in stats])\ntotal_final = sum([stats[cat]['total_output'] for cat in stats])\n\nprint(f\" Original images: {total_original}\")\nprint(f\" Final images: {total_final}\")\nprint(f\" Data augmentation ratio: {total_final/total_original:.2f}x\")\nprint(f\" Image shape: {X_data.shape[1:]}\")\nprint(f\" Data type: {X_data.dtype}\")\nprint(f\" Pixel value range: [{X_data.min():.3f}, {X_data.max():.3f}]\")\nprint(f\" Number of classes: {len(np.unique(y_data))}\")\n\nprint(\"\\n Label distribution:\")\nunique_labels, counts = np.unique(y_data, return_counts=True)\nfor label, count in zip(unique_labels, counts):\n    category_name = decode_label(label, label_encoder)\n    print(f\"   {category_name} (Label {label}): {count} images\")\n\nprint(\"\\n Preprocessing pipeline completed successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T18:40:26.274799Z","iopub.execute_input":"2025-09-25T18:40:26.275397Z","execution_failed":"2025-09-25T18:42:37.965Z"}},"outputs":[{"name":"stdout","text":" Executing complete preprocessing pipeline...\n============================================================\n Starting complete dataset preprocessing...\n\n Processing category: metal\n    metal: 2000 → 4000 images\n       Original: 2000, Augmented: 2000, Failed: 0\n\n Processing category: glass\n    glass: 2000 → 4000 images\n       Original: 2000, Augmented: 2000, Failed: 0\n\n Processing category: paper\n    paper: 2000 → 4000 images\n       Original: 2000, Augmented: 2000, Failed: 0\n\n Processing category: cardboard\n    cardboard: 2000 → 4000 images\n       Original: 2000, Augmented: 2000, Failed: 0\n\n Processing category: plastic\n    plastic: 2000 → 4000 images\n       Original: 2000, Augmented: 2000, Failed: 0\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}